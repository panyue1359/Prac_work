---
title: 贝叶斯优化
---

- 贝叶斯优化/别名：Bayesian optimization, Bayesian Global Optimization
- 贝叶斯优化/定义
  collapsed:: true
	- 属于 [[优化算法]]中的全局优化算法
	- “贝叶斯优化有两个核心过程，**先验函数(Prior Function,PF)**与**采集函数(Acquisition Function,AC)**，采集函数也可以叫**效能函数(Utility Funtcion)**，但一般还是称呼为采集函数” [Leon_winter (2019) 贝叶斯优化(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)
	- “首先贝叶斯优化当然用到了贝叶斯公式，这里不作详细证明了，它要求已经存在几个样本点（同样存在冷启动问题，后面介绍解决方案），并且通过高斯过程回归（假设超参数间符合联合高斯分布）计算前面n个点的后验概率分布，得到每一个超参数在每一个取值点的**期望均值和方差**，其中均值代表这个点最终的期望效果，均值越大表示模型最终指标越大，方差表示这个点的效果不确定性，方差越大表示这个点不确定是否可能取得最大值非常值得去探索。” [贝叶斯优化: 一种更好的超参数调优方式 - 知乎](https://zhuanlan.zhihu.com/p/29779000)
	- PF(或者表示参数模型中的参数); D1:t={(x1, y1), (x2, y2), …, (xt, yt)}表示已观测集合, xt表示决策向量, yt=f(xt)+εt表示观测值, **εt表示观测误差** @cuijiaxuBeiYeSiYouHuaFangFaHeYingYongZongShu2018，说明存在观测误差
	- "一旦我们对目标函数建了模，那么我们就能抽取合适的样本尝试计算，这就涉及到了**开发（exploitation）和探索（exploration）**之间的权衡，即模型到底是在当前最优解进一步开发，还是尝试探索新的可能解。"。。“为了编码开发探索之间的权衡，我们需要定义一个 采集函数 （Acquisition function）而度量给定下一个采样点，到底它的效果是怎样的。因此我们就可以反复计算采集函数的极大值而寻找下一个采样点。” [机器之心Pro (2017) 拟合目标函数后验分布的调参利器：贝叶斯优化](https://baijiahao.baidu.com/s?id=1576049883424742&wfr=spider&for=pc)
	- “AC主要包括**EI，PI，UCB**这几种方法，同时exploration与exploitation的平衡，也是通过AC来完成的。" [Leon_winter (2019) 贝叶斯优化(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)
	- 偏向exploitation就是“就近原则”：在已知最大值附近取点
- 贝叶斯优化/异同
  collapsed:: true
	- 智能优化方法和贝叶斯优化
	  id:: ae44e23b-a7d0-4bb7-beb0-6233de1d3011
	  collapsed:: true
		- “无模型优化算法不需要考虑模型更新问题，而贝叶斯优化在更新概率代理模型时需要高昂的计算开销。” @cuijiaxuBeiYeSiYouHuaFangFaHeYingYongZongShu2018
		- “相比无模型的优化方法，贝叶斯优化需要谨慎地选择模型和先验。在使用贝叶斯方法解决具体问题时，需要根据问题背景和专家知识选择合适的概率模型来代理黑箱函数。为贝叶斯优化选择合适的概率代理模型，甚至比选择恰当的采集函数更为重要。目前，还不存在一种通用的方法为贝叶斯优化选择合适的代理模型和先验分布，都是采取具体问题具体分析的策略。” @cuijiaxuBeiYeSiYouHuaFangFaHeYingYongZongShu2018
	- Kriging优化和贝叶斯优化
	  id:: eKDiRXMIX
	  collapsed:: true
	  id:: 684e2833-6f81-4b8d-955f-3f4057770e4b
		- [Alaya](https://www.zhihu.com/question/263567035)认为"Kriging 其实就是 GP，基于 Kriging + (EI/LCB/PI) 的(代理模型)优化方法其实也算是贝叶斯优化。。。两者都属于interpolation model（插值模型）"
		  collapsed:: true
			- 插值和拟合的区别是“区别在于假定的input中，signal/noise ratio不一样。插值假定snr很高，回归假定一般或比较低。” [匿名用户 a 回归和插值的区别是什么?](https://www.zhihu.com/question/24914211/answer/29424692)
			  id:: 621d888c-f30b-47ea-a752-b1a9d53bd78e
		- “Kriging also often restricts the prediction model to use only a small number of neighbours, making it **fit locally while ignoring global information**. Bayesian optimization normally uses all the data in order to learn a global model.” Kriging更倾向于优化模型，贝叶斯更倾向于寻优[@brochuTutorialBayesianOptimization2010]
	- ((6433377d-1234-42c8-bdef-049dff08d76d))
	- 高斯过程和贝叶斯优化的先验函数
	  id:: z8iMIEXsG
	  collapsed:: true
	  id:: 28dff24a-6b2f-4f96-83b2-2e45f1d31197
		- “为了使用贝叶斯优化，我们需要一种高效的方式来对目标函数的分布建模。。。对于这个问题， 高斯过程 （Gaussian Process）实际上生成了多维高斯分布，这种高维正态分布足够灵活以对任何目标函数进行建模。” [机器之心Pro (2017) 拟合目标函数后验分布的调参利器：贝叶斯优化](https://baijiahao.baidu.com/s?id=1576049883424742&wfr=spider&for=pc)
		- PF主要利用**高斯过程回归**(也可以是其它PF函数，但高斯过程回归用的多)" [Leon_winter (2019) 贝叶斯优化(BayesianOptimization)](https://blog.csdn.net/Leon_winter/article/details/86604553)
- 贝叶斯优化/应用
  id:: _UNmw8VQ7
  collapsed:: true
  id:: 610ee15d-9ffe-41cc-9f1c-9dc97df7ccf5
	- ((9401dc0b-b1f0-45f8-acec-d084e1e2cdb5))
	  id:: 625a7391-3b85-457f-9879-a87b51a9ce37
- 贝叶斯优化/文献
  collapsed:: true
	- [稍微深入地介绍贝叶斯优化_cqzz513524327的博客-CSDN博客](https://blog.csdn.net/cqzz513524327/article/details/72772205)
	- E. Brochu et al. (2010) A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning
	  id:: 621c867f-28a8-4593-affa-5a2c17a8a8a5
	- C.E.R.C.K.I. Williams. (2006) 《Gaussian processes for machine learning》