id:: : 612f4252-1a1f-43bb-9de7-301d43ec4ac9
别名:: 梯度提升(决策)树, gradient boosting decision tree, gradient boosting trees, GB trees, GBDT

- ## 理解
  collapsed:: true
	- [梯度提升树(GBDT)原理小结 - 刘建平Pinard - 博客园](https://www.cnblogs.com/pinard/p/6140514.html)
- "GBDT的原理很简单，就是所有弱分类器的结果相加等于预测值，然后下一个弱分类器去拟合误差函数对预测值的残差(这个残差就是预测值与真实值之间的误差)。当然了，它里面的弱分类器的表现形式就是各棵树。" [NLP-LOVE (2021) GBDT](https://github.com/NLP-LOVE/ML-NLP/blob/fda5748094d086544a034b8e9df97a5953c0f608/Machine%20Learning/3.2%20GBDT/3.2%20GBDT.md )
- "首先xgboost是Gradient Boosting的一种高效系统实现，并不是一种单一算法。**xgboost里面的基学习器除了用tree(gbtree)，也可用线性分类器(gblinear)。**而GBDT则特指梯度提升决策树算法。"[机器学习算法中 GBDT 和 XGBOOST 的区别有哪些？ - 知乎](https://www.zhihu.com/question/41354392/answer/98658997) #XGBoost
  id:: 612ee665-44cc-401b-93e4-274c38006124