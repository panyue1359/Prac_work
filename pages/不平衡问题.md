- ((642d416b-1e45-497c-85e7-619eae13a0ba))
  collapsed:: true
	- >((644652cc-61e1-40df-9a65-8f59be020b98))
- ## 含义
- 数据集不平衡的例子[机器学习中如何处理不平衡数据？ - 知乎](https://zhuanlan.zhihu.com/p/56960799)
- 确认样本不平衡是否具有代表性，能否反映真实情况，比如“六月飞雪”这样的天气本身就少见，占比例小是合理的，如果通过重采样等方法强行使之平衡，反而歪曲了真实的数据分布
- ## 有何影响
- 确认不平衡问题是否重要（小数据区域预测失败的代价VS大数据区域预测成功的收益）[机器学习中，分类中可能出现不平衡数据，那么在回归问题中有不平衡数据这一说法吗？ - Tony的回答 - 知乎](https://www.zhihu.com/question/356481912/answer/926804612)
- “而当类别不平衡时，准确率就非常具有迷惑性，而且意义不大”[如何处理数据中的「类别不平衡」？ - 微调的文章 - 知乎](https://zhuanlan.zhihu.com/p/32940093)
- ## 对策
- “重采样会明显的改变数据分布，我们的训练数据假设不再是真实数据的无偏表述。”。。“而且技术难度较大”[如何处理数据中的「类别不平衡」？ - 微调的文章 - 知乎](https://zhuanlan.zhihu.com/p/32940093)
- “基本上，在学习任务有些难度的前提下，不均衡解决方法可以归结为：通过某种方法使得不同类别的样本对于模型学习中的Loss（或梯度）贡献是比较均衡的。以消除模型对不同类别的偏向性，学习到更为本质的特征。”[样本数据量很大的情况下，样本极度不平衡（1：370）怎么解决？ - 泳鱼的回答 - 知乎](https://www.zhihu.com/question/324187407/answer/2278200010)
- “处理不平衡问题主要是从数据和算法层面考虑，数据层面的方法有增加数据、重采样、人工样本和异常值检测；算法层面的方法有集成算法和树算法、加权惩罚和改变问题”[炼丹笔记一：样本不平衡问题 - 会写代码的好厨师的文章 - 知乎](https://zhuanlan.zhihu.com/p/56882616)
- “你可以试试GBDT类算法，如Xgboost，都有处理类别不平衡的参数，关键TREE算法天生不怎么怕类别不平衡问题；哪怕就是sklearn里的逻辑回归，也有class_weight参数，直接调参就好，一般‘balance’自动平衡就可以了。这些其实也是代价敏感学习，与MetaCost不同的是，这些方法为了实现“对样本区别对待”，直接将权重作用在损失函数上，我个人将它们归类于内嵌式代价敏感学习——此类方法最大的优势是，很多机器学习工具都已经帮我们实现了，不用自己去写。”[对于一个极度不平衡的数据集，训练和测试的时候分别要注意什么？ - 知乎](https://www.zhihu.com/question/323518703/answer/678887717)
- 极不平衡数据集建议考虑异常值检测[样本数据量很大的情况下，样本极度不平衡（1：370）怎么解决？ - 泳鱼的回答 - 知乎](https://www.zhihu.com/question/324187407/answer/2278200010)