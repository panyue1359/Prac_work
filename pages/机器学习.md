别名:: machine learning, ML, artificial intelligence, AI

- # B
- [[半监督学习]]
- # K
- [[可解释性]]
- 可视化
  id:: 62903b40-9a51-43be-b6c6-89da210691c8
- # M
- [[模型评价指标]]
- # P
- 平台和语言
  collapsed:: true
	- ((2c801976-20a7-4074-9555-84c855555d96))
	- ((cf406652-b83f-4f0c-b10b-7c2b6ee2ad27))
	- ((9baa0f1a-1102-4ee5-aa94-6a68e36943cd))
	- ((264e4e53-e838-4bf6-91ce-c8a663676adc))
- 偏差-方差分析
  collapsed:: true
	- 随训练集变化，训练结果变化很大，说明方差很大
	  id:: 61cfce7c-6bb8-4182-ab46-f907856f9c2e
- # R
- 入门建议
  collapsed:: true
	- 机器学习的理想是“高针对性数据加通用算法”（傅睿卿 a），在工程应用上数据是核心，算法是工具。因此入门机器学习应该直接从实践开始，遇到问题按需学习理论（微调 a），同时要注意学习资料的时效性（微调 a）。
	- 机器学习的理论需要通过编程实现，推荐学习Python语言，其次R语言（微调 a）。pytho的机器学习库中，做传统机器学习推荐使用scikit-learn，因为“sklearn主要适合 **中小型的** 、实用机器学习项目，尤其是那种**数据量不大**且需要使用者 **手动对数据进行处理** ，并选择合适模型的项目。这类项目往往在CPU上就可以完成，对硬件要求低。”（微调 c）。
	- 入门视频课程推荐Andrew Ng的课程和林轩田的课程（desperado a），书籍推荐S. Raschka (2017) 《python机器学习》。流行的西瓜书（周志华 (2016) 《机器学习》）更适合作为参考书看。（微调 a）
	- 如无必要，不建议从深度学习开始入手（微调 a），因为深度学习的模型和理论复杂而且还在变化中（微调 a, b），硬件要求高（微调 a），调参困难（微调 b），前置课程多（微调 b）。
	- > [傅睿卿 a 如何看待「机器学习不需要数学，很多算法封装好了，调个包就行」这种说法？](https://www.zhihu.com/question/60064269/answer/172522358)
	  [微调 a 如何用3个月零基础入门「机器学习」？ - 知乎](https://zhuanlan.zhihu.com/p/29704017)
	  [微调 b 深度学习的教学和课程，与传统 CS 的教学和课程有什么区别？](https://www.zhihu.com/question/63883727/answer/225499427)
	  [微调 c 现在tensorflow和mxnet很火，是否还有必要学习scikit-learn等框架？](https://www.zhihu.com/question/53740695/answer/284428668)
	  [desperado a 机器学习最好的课程是什么？](https://www.zhihu.com/question/37031588/answer/71271829)
	  [刘建平机器学习文章和代码](https://github.com/ljpzzz/machinelearning)
- # S
- 数据集
  id:: fcb0f07e-edb1-4b97-8e86-063593051b4f
  collapsed:: true
	- 打开csv文件问题：Excel读取csv有“/”的数据会自动填充，因此一定不能用Excel读取csv文件
	- 数据集不平衡
	  id:: UsxjjcFZM
	  id:: 81580cd4-1797-4446-85fd-bf83dbad4b0e
	  collapsed:: true
		- 数据集不平衡的例子[机器学习中如何处理不平衡数据？ - 知乎](https://zhuanlan.zhihu.com/p/56960799)
		- 确认不平衡问题是否重要（小数据区域预测失败的代价VS大数据区域预测成功的收益）[机器学习中，分类中可能出现不平衡数据，那么在回归问题中有不平衡数据这一说法吗？ - Tony的回答 - 知乎](https://www.zhihu.com/question/356481912/answer/926804612)
		- 确认样本不平衡是否具有代表性，能否反映真实情况
		- “而当类别不平衡时，准确率就非常具有迷惑性，而且意义不大”[如何处理数据中的「类别不平衡」？ - 微调的文章 - 知乎](https://zhuanlan.zhihu.com/p/32940093)
		- “基本上，在学习任务有些难度的前提下，不均衡解决方法可以归结为：通过某种方法使得不同类别的样本对于模型学习中的Loss（或梯度）贡献是比较均衡的。以消除模型对不同类别的偏向性，学习到更为本质的特征。”[样本数据量很大的情况下，样本极度不平衡（1：370）怎么解决？ - 泳鱼的回答 - 知乎](https://www.zhihu.com/question/324187407/answer/2278200010)
		- “处理不平衡问题主要是从数据和算法层面考虑，数据层面的方法有增加数据、重采样、人工样本和异常值检测；算法层面的方法有集成算法和树算法、加权惩罚和改变问题”[炼丹笔记一：样本不平衡问题 - 会写代码的好厨师的文章 - 知乎](https://zhuanlan.zhihu.com/p/56882616)
	- 数据量的影响：“数据量很小，用朴素贝叶斯、逻辑回归或支持向量机；数据量适中或者较大，用树模型，优先 xgboost和lightgbm；数据量较大，尝试使用神经网络”[「机器学习」到底需要多少数据？ - 知乎](https://zhuanlan.zhihu.com/p/34523880)
	- 数据集划分："只有在同样的测试集上，两个（或以上）模型的对比才有效。".."所以，如果你的研究，是靠着比别人的模型效果来说事儿，那就一定先要弄明白对方的测试集是什么。"[如何正确使用机器学习中的训练集、验证集和测试集？ - 知乎](https://zhuanlan.zhihu.com/p/71961236)
	  id:: 626a6929-a955-4dd7-a701-9608a85c19bd
	- 可视化
	  collapsed:: true
		- Kirk[@Kirk2022]等使用t-SNE降维方法可视化AlCoCrFeMnNiV高熵合金候选样本，在t-SNE图中相近的点代表相近的成分，具体内容看不懂。
- # T
- 特征工程
  collapsed:: true
	- 别名:: feature engineering
	- 特征工程包括：[[降维]]、 [[特征选择]]、 [[特征缩放]]
- 特征抽取（feature extraction）：将声音、图像等非数字化信息转化成可用于机器学习的数字格式的技术
  id:: 61d8ef1a-fc2c-4465-b8ba-a84fdf104749
- 特征选择后如何区分不同的特征
  collapsed:: true
	- [如何在pandas中使用sklearn-fit_转换并返回dataframe而不是numpy数组？ - 问答 - Python中文网](https://www.cnpython.com/qa/31782)建议使用sklearn_pandas包的DataFrameMapper，使用方法类似于pipeline，但可以处理指定列和行
	  id:: 6176b00a-53b5-415b-adc4-ae56dc9e5c57
	- 处理后返回feature_names_in_属性值，重新组装成DataFrame
- # X
- 寻找最容易判断错误的样本（代码）
  collapsed:: true
	- ``` python
	  """
	  使用不同的随机数种子划分数据集，分析容易判错的样本
	  """
	  for i in range(11,20):
	      rege=RandomForestRegressor(random_state=0)
	      k=0
	      b=0
	      for _ in range(100,i*10,i):
	     X_trainval,X_test,y_trainval,y_test=train_test_split(foo_X,foo_y,test_size=0.2,random_state=_)
	     a=np.mean(cross_val_score(rege,X_trainval,y_trainval,cv=12))
	     #收集分数最低的随机数种子
	     if a<k:
	         k=a
	         b=_
	      X_trainval,X_test,y_trainval,y_test=train_test_split(foo_X,foo_y,test_size=0.2,random_state=b)
	      kf=KFold(n_splits=12)
	      testindex=np.array([])
	      for train_index, test_index in kf.split(X_trainval):
	     if np.all(test_index==np.array([0,1])):
	         testindex=test_index
	     else:
	         testindex=np.vstack((testindex,test_index))
	      cvscore=cross_val_score(rege,X_trainval,y_trainval,cv=12)
	      testindex[cvscore<0]=True
	      testindex[cvscore>=0]=False
	      print('对于随机数种子%s,其最容易判错的样本序号是：' %b,np.sort(X_trainval[np.array(testindex[testindex>-1],dtype=bool)].index))
	  
	  ```
	- i在1到9之间，随机数种子在0到i*10之间
	  collapsed:: true
		- 对于随机数种子1,其最容易判错的样本序号是： [ 1  3  8 12 22 24 26 27]
		  对于随机数种子2,其最容易判错的样本序号是： [ 2  3  5  8 15 17 20 27]
		  对于随机数种子15,其最容易判错的样本序号是： [ 1  2  3  6  8 10 21 24 26 29]
		  对于随机数种子20,其最容易判错的样本序号是： [ 2  3  6  7  9 11 14 16 17 19 20 22 23 24 25 26]
		  对于随机数种子15,其最容易判错的样本序号是： [ 1  2  3  6  8 10 21 24 26 29]
		  对于随机数种子30,其最容易判错的样本序号是： [ 1  2  3  5 12 14 16 18 19 20 23 29]
		  对于随机数种子56,其最容易判错的样本序号是： [ 1  6  8 19 24 25 27 28]
		  对于随机数种子56,其最容易判错的样本序号是： [ 1  6  8 19 24 25 27 28]
		  对于随机数种子72,其最容易判错的样本序号是： [ 7  8 12 13 16 18 19 24 28 29]
	- i在11到19之间，随机数种子在100到i*10之间
	  collapsed:: true
		- 对于随机数种子100,其最容易判错的样本序号是： [ 0  1  3  4  6  7  8 11 14 17 18 19 21 22 24 29]
		  对于随机数种子112,其最容易判错的样本序号是： [ 1  8  9 10 14 15 17 19 20 22 23 26]
		  对于随机数种子113,其最容易判错的样本序号是： [ 1  3  5  6  7 13 20 24 25 28]
		  对于随机数种子128,其最容易判错的样本序号是： [ 0  2  3  5 10 11 12 18 19 20 21 23 28 29]
		  对于随机数种子115,其最容易判错的样本序号是： [ 2  3  5  6  7 12 13 15 16 19 22 23 25 29]
		  对于随机数种子148,其最容易判错的样本序号是： [ 2  5  7 10 13 14 15 17 19 23 25 27 28 29]
		  对于随机数种子168,其最容易判错的样本序号是： [ 1  6  9 10 11 12 13 16 19 21 23 25]
		  对于随机数种子118,其最容易判错的样本序号是： [ 1  3  5  8 13 14 16 19 24 26]
		  对于随机数种子100,其最容易判错的样本序号是： [ 0  1  3  4  6  7  8 11 14 17 18 19 21 22 24 29]
	- 综上，最容易判错的样本是1，2，3，6，29，排除以后效果很差
	  collapsed:: true
		- 从foo_X和foo_y中排除特定的行
		  collapsed:: true
			- ``` python
			  #把要去掉的行换成Na，全是Na的行返回False，其余行返回True，最后使用索引过滤
			  foo_X.loc[[1,2,3,6,29]]=np.nan
			  foo_X=foo_X[foo_X.any(1)]
			  foo_y.loc[[1,2,3,6,29]]=np.nan
			  foo_y=foo_y[foo_y!=0]
			  
			  ```
			- 容易判错的数据多为FCC+BCC结构，增加FCC+BCC结构的数据