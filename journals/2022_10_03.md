- ## skopt (优化算法库)
  collapsed:: true
	- ((64453f0a-39cc-4099-af21-910006aa95f2))
	  collapsed:: true
		- 参考
		  collapsed:: true
			- >((644637bd-1ae9-46fa-adb6-c87fccfcdef6))
			- > ((64453fa5-c6d4-4d0d-a285-deefc03b73d8))
			- ->[贝叶斯优化的各个python实现包之间有什么区别？ - 知乎](https://www.zhihu.com/question/360767107)
			- ->T. Ueno et al. (2016) COMBO: An efficient Bayesian optimization library for materials science，适用于大规模计算
- 官网：[Scikit-Optimizer](https://scikit-optimize.github.io/stable/index.html)( skopt ), [Examples](https://scikit-optimize.github.io/stable/auto_examples/index.html)
- 使用skopt进行高斯贝叶斯全局寻优，参数设置[参考](https://scikit-optimize.github.io/stable/modules/generated/skopt.utils.use_named_args.html#skopt.utils.use_named_args)
  collapsed:: true
	- ``` python
	  #优化前先fit模型
	  #可以使用其他先验函数如forest_minimize,gbrt_minimize等
	  from skopt import gp_minimize
	  from skopt.space import Integer, Real
	  space_frac=[Real(0.1,1,name='Al'),Real(0.1,1,name='Co')\
	        ,Real(0.1,1,name='Cr'),Real(0.1,1,name='Cu')\
	        ,Real(0.1,1,name='Fe'),Real(0.1,1,name='Mn')\
	        ,Real(0.1,1,name='Ni'),Real(0.1,1,name='V')]
	  from skopt.utils import use_named_args
	  @use_named_args(space_frac)
	  def ratio_to_pred(Al,Co,Cr,Cu,Fe,Mn,Ni,V,rege=rege):
	      atomic=np.array([Al,Co,Cr,Cu,Fe,Mn,Ni,V])
	      X_pred=dataset_generator.frac_ele_emp(atomic)
	      X_pred=X_pred[frac+ele_candidate+emp_candidate].values
	      #加负号使问题转换为找最小值
	      return -rege.predict(X_pred)[0]
	  #绘制优化轮数-目标值图
	  from skopt.plots import plot_convergence
	  result=gp_minimize(ratio_to_pred,space_frac,n_calls=100\
	               ,acq_func='EI',random_state=0)
	  print("x^*=%s, f(x^*)=%.4f" % (result.x, result.fun))
	  plot_convergence(result)
	  
	  ```
- 使用skopt进行代理模型优化
  collapsed:: true
	- 不支持离散输入：[Accepting discontinuous sets for a dimension? · Issue #154 · scikit-optimize/scikit-optimize](https://github.com/scikit-optimize/scikit-optimize/issues/154)
	- [Async optimization Loop](https://scikit-optimize.github.io/stable/auto_examples/ask-and-tell.html#sphx-glr-auto-examples-ask-and-tell-py)：计算与实验流程配合
	  id:: 6226cd36-a25e-4373-83cb-99ef9dde8810
- 使用skopt进行超参数优化
  id:: 621cd17b-0af6-4990-bb83-971b3d851fc3
  collapsed:: true
	- 代码
	  
	  ``` python
	  #使用高斯过程给出不确定度
	  from skopt import gp_minimize
	  from skopt.space import Integer, Real
	  #根据实际情况定义space
	  space=[Integer(2,50,name="n_neighbors")]
	  #skopt中优化器导入多维数据需要扩展use_name_args
	  from skopt.utils import use_named_args
	  @use_named_args(space)
	  def objective(**params):
	      rege.set_params(**params)
	      return -np.mean(cross_val_score(rege, X_trainval, y_trainval, cv=13,\
	                                scoring="neg_mean_absolute_error"))
	  #贝叶斯优化调参
	  res_gp=gp_minimize(objective,space,n_calls=50,random_state=0)
	  #分数越接近0越好
	  "Best score=%.4f" %res_gp.fun
	  print("""Best parameters:%s""" % (res_gp.x))
	  
	  ```
- ## KNN
  collapsed:: true
	- 别名: K-NearestNeighbor, k最近邻
	- ((64468a02-5425-4d78-9616-62e848fbdc27))
	  collapsed:: true
		- ->[用人话讲明白近邻算法KNN - 知乎](https://zhuanlan.zhihu.com/p/79531731)
- “KNN是有监督算法，Kmeans是无监督算法，但KNN和Kmeans确实有相同之处” [用人话讲明白近邻算法KNN - 知乎](https://zhuanlan.zhihu.com/p/79531731)