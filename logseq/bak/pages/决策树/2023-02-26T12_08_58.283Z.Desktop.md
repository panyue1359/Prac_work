---
title: 决策树
---

- 决策树/别名：decision tree, DT

- 决策树/定义

- 决策树/异同
	 - 基于树的集成模型： [[梯度提升树]] , [[随机森林]]

- 决策树/应用
collapsed:: true
	 - ((81580cd4-1797-4446-85fd-bf83dbad4b0e))
		 - “你可以试试GBDT类算法，如Xgboost，都有处理类别不平衡的参数，关键TREE算法天生不怎么怕类别不平衡问题；哪怕就是sklearn里的逻辑回归，也有class_weight参数，直接调参就好，一般‘balance’自动平衡就可以了。这些其实也是代价敏感学习，与MetaCost不同的是，这些方法为了实现“对样本区别对待”，直接将权重作用在损失函数上，我个人将它们归类于内嵌式代价敏感学习——此类方法最大的优势是，很多机器学习工具都已经帮我们实现了，不用自己去写。”[对于一个极度不平衡的数据集，训练和测试的时候分别要注意什么？ - 知乎](https://www.zhihu.com/question/323518703/answer/678887717)

- 决策树/文献
collapsed:: true
	 - [这可能是你看过的最用心的【决策树算法】介绍文章 - 知乎](https://zhuanlan.zhihu.com/p/32053821)

	 - [机器学习实战（三）——决策树_呆呆的猫的博客-CSDN博客_决策树](https://blog.csdn.net/jiaoyangwm/article/details/79525237)

	 - [深入浅出理解决策树算法（一）-核心思想 - 知乎](https://zhuanlan.zhihu.com/p/26703300)

	 - [【机器学习】决策树（中）—— Random forest、Adaboost、 GBDT （非常详细） - 知乎](https://zhuanlan.zhihu.com/p/86263786)
